C:\Users\Vahid\AppData\Local\Programs\Python\Python310\python.exe C:\Users\Vahid\Desktop\SV\sv.py 
              PM25         PM10          CO2         Temp     Humidity
count  7142.000000  7142.000000  7142.000000  7142.000000  7142.000000
mean     10.328009    43.821414   258.404812    35.320161    48.073138
std       6.777525    18.074575    91.767725     1.242564     5.264367
min       0.000000     5.000000    83.000000    32.100000    27.000000
25%       5.000000    30.000000   189.000000    34.300000    46.000000
50%      10.000000    47.000000   258.000000    35.400000    49.000000
75%      14.000000    57.000000   312.000000    36.300000    52.000000
max      43.000000   127.000000   668.000000    38.300000    60.000000
              PM25         PM10          CO2         Temp     Humidity
count  1786.000000  1786.000000  1786.000000  1786.000000  1786.000000
mean     10.303944    43.911031   258.495149    35.319324    48.066042
std       6.661341    17.900673    91.672484     1.240299     5.247450
min       0.000000     6.000000    83.000000    32.300000    28.000000
25%       5.000000    30.000000   189.000000    34.300000    46.000000
50%      10.000000    47.000000   257.500000    35.400000    49.000000
75%      14.000000    57.000000   313.000000    36.300000    52.000000
max      36.000000    97.000000   627.000000    38.300000    58.000000
              PM25         PM10          CO2         Temp     Humidity
count  7142.000000  7142.000000  7142.000000  7142.000000  7142.000000
mean     10.326593    43.821922   258.406993    35.320633    48.071932
std       6.779640    18.075482    91.767527     1.246666     5.266287
min      -0.328152     4.906301    83.016254    32.105380    26.818104
25%       4.940866    30.080385   189.011349    34.273555    45.982574
50%      10.026368    47.095544   258.039902    35.413541    49.081973
75%      14.232298    56.960718   312.109653    36.273998    51.770807
max      43.003396   127.030829   668.070233    38.499577    59.896500
integrated is selected
2022-11-23 15:16:49.394767: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-11-23 15:16:49.394965: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
epoch_0_loss:  0.7576353293100283
epoch_1_loss:  0.25561442470113915
epoch_2_loss:  0.08289426466678558
epoch_3_loss:  0.039724594899225675
epoch_4_loss:  0.02005090815029253
epoch_5_loss:  0.011682818240158257
epoch_6_loss:  0.008312638065197045
epoch_7_loss:  0.00644862371335257
epoch_8_loss:  0.005166967717571877
epoch_9_loss:  0.004330346072144161
epoch_10_loss:  0.003788265888002166
epoch_11_loss:  0.0034201385324931196
epoch_12_loss:  0.0030949722327123356
epoch_13_loss:  0.0028045058600194815
epoch_14_loss:  0.002526897764522833
epoch_15_loss:  0.0022465775453078566
epoch_16_loss:  0.001995100705832954
epoch_17_loss:  0.0017568565090838898
epoch_18_loss:  0.0015534781070262584
epoch_19_loss:  0.0013873533526804138
epoch_20_loss:  0.0012624466444181946
epoch_21_loss:  0.001171542435896994
epoch_22_loss:  0.0011065487737290914
epoch_23_loss:  0.001053695245114883
epoch_24_loss:  0.00101662088350245
epoch_25_loss:  0.000989717060327243
epoch_26_loss:  0.0009663068143173231
epoch_27_loss:  0.0009476153681687677
epoch_28_loss:  0.0009251150108014634
epoch_29_loss:  0.0009014237116680887
epoch_30_loss:  0.0008815744676536199
epoch_31_loss:  0.0008626742310043452
epoch_32_loss:  0.0008453908722976601
epoch_33_loss:  0.0008242532453686924
epoch_34_loss:  0.0008049799245366544
epoch_35_loss:  0.0007867911215280857
epoch_36_loss:  0.0007674884297721347
epoch_37_loss:  0.000744226869368057
epoch_38_loss:  0.0007218026147765238
epoch_39_loss:  0.0007020728777444266
epoch_40_loss:  0.0006814563530293502
epoch_41_loss:  0.0006605804304578163
epoch_42_loss:  0.0006464575593054891
epoch_43_loss:  0.0006209944426661054
epoch_44_loss:  0.0006010732363990136
epoch_45_loss:  0.0005809508692358094
epoch_46_loss:  0.000558168373610647
epoch_47_loss:  0.0005418531981033298
epoch_48_loss:  0.000528280929980237
epoch_49_loss:  0.0005058992826222377
epoch_50_loss:  0.0004907200022151392
epoch_51_loss:  0.0004737487704559056
epoch_52_loss:  0.0004571038155825591
epoch_53_loss:  0.00044221762580130337
epoch_54_loss:  0.0004262140113589787
epoch_55_loss:  0.0004112335179746236
epoch_56_loss:  0.0004015906246668703
epoch_57_loss:  0.0003904003856745335
epoch_58_loss:  0.0003832845209516599
epoch_59_loss:  0.00037200650913230487
epoch_60_loss:  0.0003574297305121739
epoch_61_loss:  0.0003418510416380648
epoch_62_loss:  0.00033532256175615184
epoch_63_loss:  0.0003246790149811131
epoch_64_loss:  0.0003079616184732462
epoch_65_loss:  0.0002907016133319199
epoch_66_loss:  0.0002762454050363475
epoch_67_loss:  0.00026740071921508055
epoch_68_loss:  0.00026002021801044896
epoch_69_loss:  0.0002551483474645842
[0.7576353293100283, 0.25561442470113915, 0.08289426466678558, 0.039724594899225675, 0.02005090815029253, 0.011682818240158257, 0.008312638065197045, 0.00644862371335257, 0.005166967717571877, 0.004330346072144161, 0.003788265888002166, 0.0034201385324931196, 0.0030949722327123356, 0.0028045058600194815, 0.002526897764522833, 0.0022465775453078566, 0.001995100705832954, 0.0017568565090838898, 0.0015534781070262584, 0.0013873533526804138, 0.0012624466444181946, 0.001171542435896994, 0.0011065487737290914, 0.001053695245114883, 0.00101662088350245, 0.000989717060327243, 0.0009663068143173231, 0.0009476153681687677, 0.0009251150108014634, 0.0009014237116680887, 0.0008815744676536199, 0.0008626742310043452, 0.0008453908722976601, 0.0008242532453686924, 0.0008049799245366544, 0.0007867911215280857, 0.0007674884297721347, 0.000744226869368057, 0.0007218026147765238, 0.0007020728777444266, 0.0006814563530293502, 0.0006605804304578163, 0.0006464575593054891, 0.0006209944426661054, 0.0006010732363990136, 0.0005809508692358094, 0.000558168373610647, 0.0005418531981033298, 0.000528280929980237, 0.0005058992826222377, 0.0004907200022151392, 0.0004737487704559056, 0.0004571038155825591, 0.00044221762580130337, 0.0004262140113589787, 0.0004112335179746236, 0.0004015906246668703, 0.0003904003856745335, 0.0003832845209516599, 0.00037200650913230487, 0.0003574297305121739, 0.0003418510416380648, 0.00033532256175615184, 0.0003246790149811131, 0.0003079616184732462, 0.0002907016133319199, 0.0002762454050363475, 0.00026740071921508055, 0.00026002021801044896, 0.0002551483474645842]
parallel(
  (AE_encoder): Sequential(
    (0): Linear(in_features=5, out_features=4, bias=True)
    (1): ReLU()
  )
  (MemAE_encoder): Sequential(
    (0): Linear(in_features=5, out_features=4, bias=True)
    (1): ReLU()
  )
  (mem_rep): MemModule(
    (memory): MemoryUnit(mem_dim=149, fea_dim=True)
  )
  (VAE_Encoder): Encoder(
    (FC_input): Linear(in_features=5, out_features=4, bias=True)
    (FC_input2): Linear(in_features=4, out_features=4, bias=True)
    (FC_mean): Linear(in_features=4, out_features=4, bias=True)
    (FC_var): Linear(in_features=4, out_features=4, bias=True)
    (LeakyReLU): LeakyReLU(negative_slope=0.2)
  )
  (g_decoder): Linear(in_features=12, out_features=5, bias=True)
)
parallel(
  (AE_encoder): Sequential(
    (0): Linear(in_features=5, out_features=4, bias=True)
    (1): ReLU()
  )
  (MemAE_encoder): Sequential(
    (0): Linear(in_features=5, out_features=4, bias=True)
    (1): ReLU()
  )
  (mem_rep): MemModule(
    (memory): MemoryUnit(mem_dim=149, fea_dim=True)
  )
  (VAE_Encoder): Encoder(
    (FC_input): Linear(in_features=5, out_features=4, bias=True)
    (FC_input2): Linear(in_features=4, out_features=4, bias=True)
    (FC_mean): Linear(in_features=4, out_features=4, bias=True)
    (FC_var): Linear(in_features=4, out_features=4, bias=True)
    (LeakyReLU): LeakyReLU(negative_slope=0.2)
  )
  (g_decoder): Linear(in_features=12, out_features=5, bias=True)
)
MSE for integrated:  0.5590411385801639
RR for integrated:  0.999759762897306
MAE for integrated:  0.2902352834286442
MAPE for integrated:  1.2852068947788409
MAE is selected
epoch_0_loss:  0.8404444305192172
epoch_1_loss:  0.49808911665721434
epoch_2_loss:  0.4439821403643267
epoch_3_loss:  0.37170284667591014
epoch_4_loss:  0.31258947913266577
epoch_5_loss:  0.29217050421307655
epoch_6_loss:  0.2820451371996529
epoch_7_loss:  0.27595480385822463
epoch_8_loss:  0.271823442143536
epoch_9_loss:  0.26808908374014995
epoch_10_loss:  0.2637164071349631
epoch_11_loss:  0.2575228458242525
epoch_12_loss:  0.24712720450757944
epoch_13_loss:  0.22779126161692084
epoch_14_loss:  0.19971371579570896
epoch_15_loss:  0.17040425299904022
epoch_16_loss:  0.14568023655432996
epoch_17_loss:  0.1256560438647443
epoch_18_loss:  0.10997033702145435
epoch_19_loss:  0.09803213496375018
epoch_20_loss:  0.08916129259238029
epoch_21_loss:  0.08242768493802549
epoch_22_loss:  0.07728847209477462
epoch_23_loss:  0.07326944478279832
epoch_24_loss:  0.07017554507869203
epoch_25_loss:  0.06781728469783108
epoch_26_loss:  0.06602521183595658
epoch_27_loss:  0.06461061977812683
epoch_28_loss:  0.06342752852168866
epoch_29_loss:  0.062430260493511344
epoch_30_loss:  0.061585844900788375
epoch_31_loss:  0.060860856843997065
epoch_32_loss:  0.06019948201613721
epoch_33_loss:  0.05962303082687985
epoch_34_loss:  0.059086500153150444
epoch_35_loss:  0.05857265656577465
epoch_36_loss:  0.05810607683898687
epoch_37_loss:  0.05766893599169784
epoch_38_loss:  0.05724748344412551
epoch_39_loss:  0.05685323517281648
epoch_40_loss:  0.056455820207799635
epoch_41_loss:  0.05615721534788083
epoch_42_loss:  0.05568906302472631
epoch_43_loss:  0.055224906515103964
epoch_44_loss:  0.05472080093272264
epoch_45_loss:  0.054127376651037284
epoch_46_loss:  0.053397172457192395
epoch_47_loss:  0.05239886021950372
epoch_48_loss:  0.050938282719117045
epoch_49_loss:  0.04847911487919824
epoch_50_loss:  0.043591024196078895
epoch_51_loss:  0.03568008897978449
epoch_52_loss:  0.027864102496594337
epoch_53_loss:  0.02246411685818544
epoch_54_loss:  0.01894958383629377
epoch_55_loss:  0.016589647735360095
epoch_56_loss:  0.014872353198334382
epoch_57_loss:  0.013598835488049589
epoch_58_loss:  0.012647568342769224
epoch_59_loss:  0.011926178142395927
epoch_60_loss:  0.011384873873896407
epoch_61_loss:  0.010952154712806798
epoch_62_loss:  0.01060809303200162
epoch_63_loss:  0.010348900858043502
epoch_64_loss:  0.010136921327718339
epoch_65_loss:  0.009960231825361042
epoch_66_loss:  0.00981604240733522
epoch_67_loss:  0.009660002094089008
epoch_68_loss:  0.009525867458859975
epoch_69_loss:  0.009405637376832726
[0.8404444305192172, 0.49808911665721434, 0.4439821403643267, 0.37170284667591014, 0.31258947913266577, 0.29217050421307655, 0.2820451371996529, 0.27595480385822463, 0.271823442143536, 0.26808908374014995, 0.2637164071349631, 0.2575228458242525, 0.24712720450757944, 0.22779126161692084, 0.19971371579570896, 0.17040425299904022, 0.14568023655432996, 0.1256560438647443, 0.10997033702145435, 0.09803213496375018, 0.08916129259238029, 0.08242768493802549, 0.07728847209477462, 0.07326944478279832, 0.07017554507869203, 0.06781728469783108, 0.06602521183595658, 0.06461061977812683, 0.06342752852168866, 0.062430260493511344, 0.061585844900788375, 0.060860856843997065, 0.06019948201613721, 0.05962303082687985, 0.059086500153150444, 0.05857265656577465, 0.05810607683898687, 0.05766893599169784, 0.05724748344412551, 0.05685323517281648, 0.056455820207799635, 0.05615721534788083, 0.05568906302472631, 0.055224906515103964, 0.05472080093272264, 0.054127376651037284, 0.053397172457192395, 0.05239886021950372, 0.050938282719117045, 0.04847911487919824, 0.043591024196078895, 0.03568008897978449, 0.027864102496594337, 0.02246411685818544, 0.01894958383629377, 0.016589647735360095, 0.014872353198334382, 0.013598835488049589, 0.012647568342769224, 0.011926178142395927, 0.011384873873896407, 0.010952154712806798, 0.01060809303200162, 0.010348900858043502, 0.010136921327718339, 0.009960231825361042, 0.00981604240733522, 0.009660002094089008, 0.009525867458859975, 0.009405637376832726]
MemAE(
  (encoder): Sequential(
    (0): Linear(in_features=5, out_features=4, bias=True)
    (1): ReLU()
  )
  (mem_rep): MemModule(
    (memory): MemoryUnit(mem_dim=149, fea_dim=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=4, out_features=5, bias=True)
  )
)
MemAE(
  (encoder): Sequential(
    (0): Linear(in_features=5, out_features=4, bias=True)
    (1): ReLU()
  )
  (mem_rep): MemModule(
    (memory): MemoryUnit(mem_dim=149, fea_dim=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=4, out_features=5, bias=True)
  )
)
MSE for MAE:  18.663885217345946
RR for MAE:  0.9876554005699931
MAE for MAE:  1.9256126234593334
MAPE for MAE:  13.53894218289404
AE is selected
epoch_0_loss:  0.8366117364706357
epoch_1_loss:  0.3874820549124424
epoch_2_loss:  0.24545185445527903
epoch_3_loss:  0.15631777258703378
epoch_4_loss:  0.09222154168518562
epoch_5_loss:  0.06639455441261732
epoch_6_loss:  0.05284356987579518
epoch_7_loss:  0.043533693837685634
epoch_8_loss:  0.03602287423893638
epoch_9_loss:  0.029617868491774606
epoch_10_loss:  0.024221279871883918
epoch_11_loss:  0.019796855077791307
epoch_12_loss:  0.016327740095446297
epoch_13_loss:  0.01370354317141539
epoch_14_loss:  0.011762254048699067
epoch_15_loss:  0.010358934741060758
epoch_16_loss:  0.009347419201467306
epoch_17_loss:  0.008626029226931401
epoch_18_loss:  0.00810794859024618
epoch_19_loss:  0.007727990241978374
epoch_20_loss:  0.007449565059593481
epoch_21_loss:  0.007245069059023378
epoch_22_loss:  0.007096016691022535
epoch_23_loss:  0.006990407725764339
epoch_24_loss:  0.006914495330791867
epoch_25_loss:  0.006860181979657994
epoch_26_loss:  0.0068209872153374455
epoch_27_loss:  0.006791594306457426
epoch_28_loss:  0.006769096899644175
epoch_29_loss:  0.006751793773269056
epoch_30_loss:  0.006738195632926785
epoch_31_loss:  0.006727390272998792
epoch_32_loss:  0.006718832941172679
epoch_33_loss:  0.0067119864222731545
epoch_34_loss:  0.006706258106938968
epoch_35_loss:  0.006701513879276427
epoch_36_loss:  0.006697390970023261
epoch_37_loss:  0.006693808295001223
epoch_38_loss:  0.006690725981631788
epoch_39_loss:  0.006688006726860072
epoch_40_loss:  0.006685550777850389
epoch_41_loss:  0.006683395178622532
epoch_42_loss:  0.006681613451296647
epoch_43_loss:  0.006679760595112755
epoch_44_loss:  0.006678259873619422
epoch_45_loss:  0.006676697540842461
epoch_46_loss:  0.006675247861880973
epoch_47_loss:  0.006673896207554542
epoch_48_loss:  0.006672630726862606
epoch_49_loss:  0.006671431405905139
epoch_50_loss:  0.006670140594586616
epoch_51_loss:  0.006669109675315543
epoch_52_loss:  0.006668038202852912
epoch_53_loss:  0.006667119768991828
epoch_54_loss:  0.006666193935401842
epoch_55_loss:  0.006665264732498318
epoch_56_loss:  0.006664348785869835
epoch_57_loss:  0.006663422536391259
epoch_58_loss:  0.0066625017089128906
epoch_59_loss:  0.006661576839202754
epoch_60_loss:  0.006660675529603096
epoch_61_loss:  0.006659837152617586
epoch_62_loss:  0.006658929874978963
epoch_63_loss:  0.006657997533568835
epoch_64_loss:  0.006657089550082744
epoch_65_loss:  0.00665616896188085
epoch_66_loss:  0.006655271312605602
epoch_67_loss:  0.006654364472521495
epoch_68_loss:  0.006653466844358564
epoch_69_loss:  0.0066525816451157025
[0.8366117364706357, 0.3874820549124424, 0.24545185445527903, 0.15631777258703378, 0.09222154168518562, 0.06639455441261732, 0.05284356987579518, 0.043533693837685634, 0.03602287423893638, 0.029617868491774606, 0.024221279871883918, 0.019796855077791307, 0.016327740095446297, 0.01370354317141539, 0.011762254048699067, 0.010358934741060758, 0.009347419201467306, 0.008626029226931401, 0.00810794859024618, 0.007727990241978374, 0.007449565059593481, 0.007245069059023378, 0.007096016691022535, 0.006990407725764339, 0.006914495330791867, 0.006860181979657994, 0.0068209872153374455, 0.006791594306457426, 0.006769096899644175, 0.006751793773269056, 0.006738195632926785, 0.006727390272998792, 0.006718832941172679, 0.0067119864222731545, 0.006706258106938968, 0.006701513879276427, 0.006697390970023261, 0.006693808295001223, 0.006690725981631788, 0.006688006726860072, 0.006685550777850389, 0.006683395178622532, 0.006681613451296647, 0.006679760595112755, 0.006678259873619422, 0.006676697540842461, 0.006675247861880973, 0.006673896207554542, 0.006672630726862606, 0.006671431405905139, 0.006670140594586616, 0.006669109675315543, 0.006668038202852912, 0.006667119768991828, 0.006666193935401842, 0.006665264732498318, 0.006664348785869835, 0.006663422536391259, 0.0066625017089128906, 0.006661576839202754, 0.006660675529603096, 0.006659837152617586, 0.006658929874978963, 0.006657997533568835, 0.006657089550082744, 0.00665616896188085, 0.006655271312605602, 0.006654364472521495, 0.006653466844358564, 0.0066525816451157025]
base_AE(
  (encoder): Sequential(
    (0): Linear(in_features=5, out_features=4, bias=True)
    (1): ReLU()
  )
  (decoder): Sequential(
    (0): Linear(in_features=4, out_features=5, bias=True)
  )
)
base_AE(
  (encoder): Sequential(
    (0): Linear(in_features=5, out_features=4, bias=True)
    (1): ReLU()
  )
  (decoder): Sequential(
    (0): Linear(in_features=4, out_features=5, bias=True)
  )
)
MSE for AE:  1.9583687563256489
RR for AE:  0.9903854876455409
MAE for AE:  0.8100879794598131
MAPE for AE:  130.58272989223306
DAE is selected
epoch_0_loss:  0.9139641035004045
epoch_1_loss:  0.4411001157558225
epoch_2_loss:  0.29148942232797004
epoch_3_loss:  0.21342650089779744
epoch_4_loss:  0.13832573473867674
epoch_5_loss:  0.08576697208492709
epoch_6_loss:  0.05560856501660947
epoch_7_loss:  0.039648398157587465
epoch_8_loss:  0.030104754556675443
epoch_9_loss:  0.023406980627942928
epoch_10_loss:  0.018458909061543287
epoch_11_loss:  0.014884894692182928
epoch_12_loss:  0.012389595606620925
epoch_13_loss:  0.010673233086629267
epoch_14_loss:  0.009481763518339263
epoch_15_loss:  0.008650333453299382
epoch_16_loss:  0.00807624555000352
epoch_17_loss:  0.007688343298855044
epoch_18_loss:  0.0074289430993124735
epoch_19_loss:  0.0072568261050912726
epoch_20_loss:  0.007140242177626637
epoch_21_loss:  0.007060207849396694
epoch_22_loss:  0.0070038580822176
epoch_23_loss:  0.006963484705229513
epoch_24_loss:  0.0069339187407215196
epoch_25_loss:  0.0069115757447943795
epoch_26_loss:  0.006893671728657748
epoch_27_loss:  0.00687884639075872
epoch_28_loss:  0.006866372861326834
epoch_29_loss:  0.006855625265513138
epoch_30_loss:  0.006846315105573435
epoch_31_loss:  0.006838163231392129
epoch_32_loss:  0.006830903164557282
epoch_33_loss:  0.006824457281864999
epoch_34_loss:  0.006818691180349221
epoch_35_loss:  0.006813484235421075
epoch_36_loss:  0.0068086613268036915
epoch_37_loss:  0.006804146076134732
epoch_38_loss:  0.0067998931393564435
epoch_39_loss:  0.006795896327120504
epoch_40_loss:  0.006792136944610531
epoch_41_loss:  0.006788592790273719
epoch_42_loss:  0.006785281254445968
epoch_43_loss:  0.006782178824365668
epoch_44_loss:  0.006779238398799151
epoch_45_loss:  0.006776503585580118
epoch_46_loss:  0.006773934958567908
epoch_47_loss:  0.006771527282500318
epoch_48_loss:  0.006769279429863755
epoch_49_loss:  0.006767171207093046
epoch_50_loss:  0.0067651810647423455
epoch_51_loss:  0.006763320944498724
epoch_52_loss:  0.006761571465636618
epoch_53_loss:  0.006759946340059875
epoch_54_loss:  0.006758412961820557
epoch_55_loss:  0.006756967636642628
epoch_56_loss:  0.006755638393331613
epoch_57_loss:  0.006754367115613519
epoch_58_loss:  0.0067531785812249235
epoch_59_loss:  0.006752066510144627
epoch_60_loss:  0.006751018639566838
epoch_61_loss:  0.006750036209430858
epoch_62_loss:  0.006749104115160092
epoch_63_loss:  0.0067482233356747435
epoch_64_loss:  0.006747386679335069
epoch_65_loss:  0.006746603340416989
epoch_66_loss:  0.006745845293273485
epoch_67_loss:  0.006745130775610094
epoch_68_loss:  0.006744440347007739
epoch_69_loss:  0.006743761667746485
[0.9139641035004045, 0.4411001157558225, 0.29148942232797004, 0.21342650089779744, 0.13832573473867674, 0.08576697208492709, 0.05560856501660947, 0.039648398157587465, 0.030104754556675443, 0.023406980627942928, 0.018458909061543287, 0.014884894692182928, 0.012389595606620925, 0.010673233086629267, 0.009481763518339263, 0.008650333453299382, 0.00807624555000352, 0.007688343298855044, 0.0074289430993124735, 0.0072568261050912726, 0.007140242177626637, 0.007060207849396694, 0.0070038580822176, 0.006963484705229513, 0.0069339187407215196, 0.0069115757447943795, 0.006893671728657748, 0.00687884639075872, 0.006866372861326834, 0.006855625265513138, 0.006846315105573435, 0.006838163231392129, 0.006830903164557282, 0.006824457281864999, 0.006818691180349221, 0.006813484235421075, 0.0068086613268036915, 0.006804146076134732, 0.0067998931393564435, 0.006795896327120504, 0.006792136944610531, 0.006788592790273719, 0.006785281254445968, 0.006782178824365668, 0.006779238398799151, 0.006776503585580118, 0.006773934958567908, 0.006771527282500318, 0.006769279429863755, 0.006767171207093046, 0.0067651810647423455, 0.006763320944498724, 0.006761571465636618, 0.006759946340059875, 0.006758412961820557, 0.006756967636642628, 0.006755638393331613, 0.006754367115613519, 0.0067531785812249235, 0.006752066510144627, 0.006751018639566838, 0.006750036209430858, 0.006749104115160092, 0.0067482233356747435, 0.006747386679335069, 0.006746603340416989, 0.006745845293273485, 0.006745130775610094, 0.006744440347007739, 0.006743761667746485]
base_AE(
  (encoder): Sequential(
    (0): Linear(in_features=5, out_features=4, bias=True)
    (1): ReLU()
  )
  (decoder): Sequential(
    (0): Linear(in_features=4, out_features=5, bias=True)
  )
)
base_AE(
  (encoder): Sequential(
    (0): Linear(in_features=5, out_features=4, bias=True)
    (1): ReLU()
  )
  (decoder): Sequential(
    (0): Linear(in_features=4, out_features=5, bias=True)
  )
)
MSE for DAE:  1.8568592466437608
RR for DAE:  0.9915203366451371
MAE for DAE:  0.7817306963376746
MAPE for DAE:  8.276549184699649
VAE is selected
Encoder(
  (FC_input): Linear(in_features=5, out_features=4, bias=True)
  (FC_input2): Linear(in_features=4, out_features=4, bias=True)
  (FC_mean): Linear(in_features=4, out_features=4, bias=True)
  (FC_var): Linear(in_features=4, out_features=4, bias=True)
  (LeakyReLU): LeakyReLU(negative_slope=0.2)
)
Decoder(
  (FC_hidden): Linear(in_features=4, out_features=4, bias=True)
  (FC_hidden2): Linear(in_features=4, out_features=4, bias=True)
  (FC_output): Linear(in_features=4, out_features=5, bias=True)
  (LeakyReLU): LeakyReLU(negative_slope=0.2)
)
epoch_0_loss:  1.0399702188590956
epoch_1_loss:  0.6221822953369084
epoch_2_loss:  0.35450524484311774
epoch_3_loss:  0.3034654462509727
epoch_4_loss:  0.26869551593721935
epoch_5_loss:  0.24269981061955803
epoch_6_loss:  0.2235501032974307
epoch_7_loss:  0.20941829387800695
epoch_8_loss:  0.1976270130761471
epoch_9_loss:  0.18833210342147222
epoch_10_loss:  0.18078011027582763
epoch_11_loss:  0.17321542280343766
epoch_12_loss:  0.16511327571464401
epoch_13_loss:  0.1576413311845238
epoch_14_loss:  0.15114704287777844
epoch_15_loss:  0.1450886906223707
epoch_16_loss:  0.13996538675566844
epoch_17_loss:  0.13537090997473758
epoch_18_loss:  0.13147887516142265
epoch_19_loss:  0.12813755357994566
epoch_20_loss:  0.12522106917539272
epoch_21_loss:  0.12252383055093201
epoch_22_loss:  0.12024403669723972
epoch_23_loss:  0.11815685251369114
epoch_24_loss:  0.11630861389181321
epoch_25_loss:  0.11469082972782253
epoch_26_loss:  0.1131708171928874
epoch_27_loss:  0.11173904145029742
epoch_28_loss:  0.11043135814526232
epoch_29_loss:  0.10911910879110892
epoch_30_loss:  0.10785000247298202
epoch_31_loss:  0.10656471584950346
epoch_32_loss:  0.10524366781661805
epoch_33_loss:  0.10389643080158349
epoch_34_loss:  0.10249633283286583
epoch_35_loss:  0.10103092438697703
epoch_36_loss:  0.09943881706131046
epoch_37_loss:  0.09773460099207268
epoch_38_loss:  0.09593003306148327
epoch_39_loss:  0.09408966207111626
epoch_40_loss:  0.09225978943787855
epoch_41_loss:  0.09045654214871897
epoch_42_loss:  0.08875147459137044
epoch_43_loss:  0.08723515825022
epoch_44_loss:  0.08585167387337567
epoch_45_loss:  0.08456109775980516
epoch_46_loss:  0.08337795572640054
epoch_47_loss:  0.08217554504134414
epoch_48_loss:  0.0810281870340891
epoch_49_loss:  0.07976703417289038
epoch_50_loss:  0.07847556718188449
epoch_51_loss:  0.07710598882207251
epoch_52_loss:  0.07562890635311958
epoch_53_loss:  0.0739517397106642
epoch_54_loss:  0.07213201304238963
epoch_55_loss:  0.06991258571618093
epoch_56_loss:  0.06737719271521127
epoch_57_loss:  0.06468481515693132
epoch_58_loss:  0.061963775472939166
epoch_59_loss:  0.05920303781869486
epoch_60_loss:  0.05650746015391334
epoch_61_loss:  0.05397169588816292
epoch_62_loss:  0.051486082365697405
epoch_63_loss:  0.0491091069620587
epoch_64_loss:  0.04683250535758866
epoch_65_loss:  0.04472459149305354
epoch_66_loss:  0.04279666290477418
epoch_67_loss:  0.04117654854449695
epoch_68_loss:  0.039594559246202685
epoch_69_loss:  0.03837126795791922
[1.0399702188590956, 0.6221822953369084, 0.35450524484311774, 0.3034654462509727, 0.26869551593721935, 0.24269981061955803, 0.2235501032974307, 0.20941829387800695, 0.1976270130761471, 0.18833210342147222, 0.18078011027582763, 0.17321542280343766, 0.16511327571464401, 0.1576413311845238, 0.15114704287777844, 0.1450886906223707, 0.13996538675566844, 0.13537090997473758, 0.13147887516142265, 0.12813755357994566, 0.12522106917539272, 0.12252383055093201, 0.12024403669723972, 0.11815685251369114, 0.11630861389181321, 0.11469082972782253, 0.1131708171928874, 0.11173904145029742, 0.11043135814526232, 0.10911910879110892, 0.10785000247298202, 0.10656471584950346, 0.10524366781661805, 0.10389643080158349, 0.10249633283286583, 0.10103092438697703, 0.09943881706131046, 0.09773460099207268, 0.09593003306148327, 0.09408966207111626, 0.09225978943787855, 0.09045654214871897, 0.08875147459137044, 0.08723515825022, 0.08585167387337567, 0.08456109775980516, 0.08337795572640054, 0.08217554504134414, 0.0810281870340891, 0.07976703417289038, 0.07847556718188449, 0.07710598882207251, 0.07562890635311958, 0.0739517397106642, 0.07213201304238963, 0.06991258571618093, 0.06737719271521127, 0.06468481515693132, 0.061963775472939166, 0.05920303781869486, 0.05650746015391334, 0.05397169588816292, 0.051486082365697405, 0.0491091069620587, 0.04683250535758866, 0.04472459149305354, 0.04279666290477418, 0.04117654854449695, 0.039594559246202685, 0.03837126795791922]
VAE(
  (Encoder): Encoder(
    (FC_input): Linear(in_features=5, out_features=4, bias=True)
    (FC_input2): Linear(in_features=4, out_features=4, bias=True)
    (FC_mean): Linear(in_features=4, out_features=4, bias=True)
    (FC_var): Linear(in_features=4, out_features=4, bias=True)
    (LeakyReLU): LeakyReLU(negative_slope=0.2)
  )
  (Decoder): Decoder(
    (FC_hidden): Linear(in_features=4, out_features=4, bias=True)
    (FC_hidden2): Linear(in_features=4, out_features=4, bias=True)
    (FC_output): Linear(in_features=4, out_features=5, bias=True)
    (LeakyReLU): LeakyReLU(negative_slope=0.2)
  )
)
VAE(
  (Encoder): Encoder(
    (FC_input): Linear(in_features=5, out_features=4, bias=True)
    (FC_input2): Linear(in_features=4, out_features=4, bias=True)
    (FC_mean): Linear(in_features=4, out_features=4, bias=True)
    (FC_var): Linear(in_features=4, out_features=4, bias=True)
    (LeakyReLU): LeakyReLU(negative_slope=0.2)
  )
  (Decoder): Decoder(
    (FC_hidden): Linear(in_features=4, out_features=4, bias=True)
    (FC_hidden2): Linear(in_features=4, out_features=4, bias=True)
    (FC_output): Linear(in_features=4, out_features=5, bias=True)
    (LeakyReLU): LeakyReLU(negative_slope=0.2)
  )
)
MSE for VAE:  270.91847863578624
RR for VAE:  0.6122528709609221
MAE for VAE:  7.395802360656764
MAPE for VAE:  14.38531618067067
MVAE is selected
Encoder(
  (FC_input): Linear(in_features=5, out_features=4, bias=True)
  (FC_input2): Linear(in_features=4, out_features=4, bias=True)
  (FC_mean): Linear(in_features=4, out_features=4, bias=True)
  (FC_var): Linear(in_features=4, out_features=4, bias=True)
  (LeakyReLU): LeakyReLU(negative_slope=0.2)
)
Decoder(
  (FC_hidden): Linear(in_features=4, out_features=4, bias=True)
  (FC_hidden2): Linear(in_features=4, out_features=4, bias=True)
  (FC_output): Linear(in_features=4, out_features=5, bias=True)
  (LeakyReLU): LeakyReLU(negative_slope=0.2)
)
epoch_0_loss:  1.0084380205197494
epoch_1_loss:  0.7702135055276242
epoch_2_loss:  0.484237644494458
epoch_3_loss:  0.4507023104858613
epoch_4_loss:  0.4408289642075887
epoch_5_loss:  0.4340999731171988
epoch_6_loss:  0.4292393306305646
epoch_7_loss:  0.4251716397573923
epoch_8_loss:  0.4212981853616841
epoch_9_loss:  0.4170242587998468
epoch_10_loss:  0.4121324227322104
epoch_11_loss:  0.40554335043331763
epoch_12_loss:  0.39359715394502953
epoch_13_loss:  0.35286928404839013
epoch_14_loss:  0.2797635779904504
epoch_15_loss:  0.2319356952195438
epoch_16_loss:  0.20148938407925734
epoch_17_loss:  0.17744536547170098
epoch_18_loss:  0.15891883045298552
epoch_19_loss:  0.14608493022730148
epoch_20_loss:  0.1365413902617006
epoch_21_loss:  0.12997666688370776
epoch_22_loss:  0.12493144570271117
epoch_23_loss:  0.12083596775118975
epoch_24_loss:  0.11713250089530071
epoch_25_loss:  0.1138093834783654
epoch_26_loss:  0.1107320816350842
epoch_27_loss:  0.10785567532345985
epoch_28_loss:  0.10514301186619424
epoch_29_loss:  0.10264382492726759
epoch_30_loss:  0.10033514898904965
epoch_31_loss:  0.09812487512894728
epoch_32_loss:  0.09612024440045748
epoch_33_loss:  0.09435764600345993
epoch_34_loss:  0.09261120358254193
epoch_35_loss:  0.0910222831417914
epoch_36_loss:  0.08936273906267728
epoch_37_loss:  0.08765968252706244
epoch_38_loss:  0.0858591798451472
epoch_39_loss:  0.0838665191742312
epoch_40_loss:  0.08147007488533697
epoch_41_loss:  0.07856736199762615
epoch_42_loss:  0.07543712319293808
epoch_43_loss:  0.07235612714603099
epoch_44_loss:  0.06936820226015541
epoch_45_loss:  0.06633629003012928
epoch_46_loss:  0.06321774825705562
epoch_47_loss:  0.060183440003306374
epoch_48_loss:  0.0570299814005361
epoch_49_loss:  0.05354247722204632
epoch_50_loss:  0.049716629051005226
epoch_51_loss:  0.045666005410573744
epoch_52_loss:  0.042124974252120806
epoch_53_loss:  0.039503186687003825
epoch_54_loss:  0.03756889629728236
epoch_55_loss:  0.03612260508780014
epoch_56_loss:  0.03497530758888377
epoch_57_loss:  0.03403999213880488
epoch_58_loss:  0.033277125302605695
epoch_59_loss:  0.03260745177129182
epoch_60_loss:  0.03203094023958191
epoch_61_loss:  0.031517019787131666
epoch_62_loss:  0.031075896842706948
epoch_63_loss:  0.03065619842553136
epoch_64_loss:  0.03028478505760237
epoch_65_loss:  0.02996926069870017
epoch_66_loss:  0.029786058916410136
epoch_67_loss:  0.029419348577856174
epoch_68_loss:  0.029232675534021618
epoch_69_loss:  0.02904053861724546
[1.0084380205197494, 0.7702135055276242, 0.484237644494458, 0.4507023104858613, 0.4408289642075887, 0.4340999731171988, 0.4292393306305646, 0.4251716397573923, 0.4212981853616841, 0.4170242587998468, 0.4121324227322104, 0.40554335043331763, 0.39359715394502953, 0.35286928404839013, 0.2797635779904504, 0.2319356952195438, 0.20148938407925734, 0.17744536547170098, 0.15891883045298552, 0.14608493022730148, 0.1365413902617006, 0.12997666688370776, 0.12493144570271117, 0.12083596775118975, 0.11713250089530071, 0.1138093834783654, 0.1107320816350842, 0.10785567532345985, 0.10514301186619424, 0.10264382492726759, 0.10033514898904965, 0.09812487512894728, 0.09612024440045748, 0.09435764600345993, 0.09261120358254193, 0.0910222831417914, 0.08936273906267728, 0.08765968252706244, 0.0858591798451472, 0.0838665191742312, 0.08147007488533697, 0.07856736199762615, 0.07543712319293808, 0.07235612714603099, 0.06936820226015541, 0.06633629003012928, 0.06321774825705562, 0.060183440003306374, 0.0570299814005361, 0.05354247722204632, 0.049716629051005226, 0.045666005410573744, 0.042124974252120806, 0.039503186687003825, 0.03756889629728236, 0.03612260508780014, 0.03497530758888377, 0.03403999213880488, 0.033277125302605695, 0.03260745177129182, 0.03203094023958191, 0.031517019787131666, 0.031075896842706948, 0.03065619842553136, 0.03028478505760237, 0.02996926069870017, 0.029786058916410136, 0.029419348577856174, 0.029232675534021618, 0.02904053861724546]
MVAE(
  (Encoder): Encoder(
    (FC_input): Linear(in_features=5, out_features=4, bias=True)
    (FC_input2): Linear(in_features=4, out_features=4, bias=True)
    (FC_mean): Linear(in_features=4, out_features=4, bias=True)
    (FC_var): Linear(in_features=4, out_features=4, bias=True)
    (LeakyReLU): LeakyReLU(negative_slope=0.2)
  )
  (Decoder): Decoder(
    (FC_hidden): Linear(in_features=4, out_features=4, bias=True)
    (FC_hidden2): Linear(in_features=4, out_features=4, bias=True)
    (FC_output): Linear(in_features=4, out_features=5, bias=True)
    (LeakyReLU): LeakyReLU(negative_slope=0.2)
  )
  (mem_rep): MemModule(
    (memory): MemoryUnit(mem_dim=149, fea_dim=True)
  )
)
MVAE(
  (Encoder): Encoder(
    (FC_input): Linear(in_features=5, out_features=4, bias=True)
    (FC_input2): Linear(in_features=4, out_features=4, bias=True)
    (FC_mean): Linear(in_features=4, out_features=4, bias=True)
    (FC_var): Linear(in_features=4, out_features=4, bias=True)
    (LeakyReLU): LeakyReLU(negative_slope=0.2)
  )
  (Decoder): Decoder(
    (FC_hidden): Linear(in_features=4, out_features=4, bias=True)
    (FC_hidden2): Linear(in_features=4, out_features=4, bias=True)
    (FC_output): Linear(in_features=4, out_features=5, bias=True)
    (LeakyReLU): LeakyReLU(negative_slope=0.2)
  )
  (mem_rep): MemModule(
    (memory): MemoryUnit(mem_dim=149, fea_dim=True)
  )
)
MSE for MVAE:  378.5545584283403
RR for MVAE:  0.5248957542714042
MAE for MVAE:  8.211202639361195
MAPE for MVAE:  16.02371959060158

Process finished with exit code 0
